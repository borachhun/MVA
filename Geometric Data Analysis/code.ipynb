{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkvzgiy_EXy7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w69kwqZ0e8mT"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knf-ocC8fG7V"
      },
      "source": [
        "## AT&T Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2yjZJmo-wod"
      },
      "outputs": [],
      "source": [
        "X, _ = fetch_olivetti_faces(return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVR7eP9be-RX"
      },
      "source": [
        "## EMNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW61732YJEI8"
      },
      "outputs": [],
      "source": [
        "emnist = datasets.EMNIST(\n",
        "    root = 'data',\n",
        "    split = 'byclass',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.ToTensor()\n",
        ")\n",
        "dataloader = DataLoader(emnist, batch_size=697932, shuffle=False)\n",
        "X, y = next(iter(dataloader))\n",
        "X = [ X[torch.where(y == i)[0][:80]].flatten(start_dim=1) for i in range(10,36) ]\n",
        "X = torch.cat(X, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlTA9MYXfNL9"
      },
      "source": [
        "## Coil20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvnTMFHCf6dH"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "%cd ./data\n",
        "!wget http://www.cs.columbia.edu/CAVE/databases/SLAM_coil-20_coil-100/coil-20/coil-20-proc.zip\n",
        "!unzip coil-20-proc.zip\n",
        "%cd ..\n",
        "\n",
        "coil20 = datasets.ImageFolder(\n",
        "    './data',\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(1),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "dataloader = DataLoader(coil20, batch_size=1440, shuffle=False)\n",
        "X, _ = next(iter(dataloader))\n",
        "X = X.flatten(start_dim=1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNsHXD3VpkeM"
      },
      "source": [
        "# Initializations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZMLF1ODOMl_"
      },
      "outputs": [],
      "source": [
        "def centers_from_pca(X, k):\n",
        "    X_pca = PCA(n_components=k).fit_transform(X)\n",
        "    y_pca = KMeans(n_clusters=k, init=centers_for_kmeanspp(X_pca, k), n_init=1, algorithm='lloyd').fit_predict(X_pca)\n",
        "\n",
        "    centers = []\n",
        "    for i in range(k):\n",
        "        X_in_cluster = X[np.nonzero(y_pca == i)]\n",
        "        centers.append(np.sum(X_in_cluster, axis=0) / X_in_cluster.shape[0])\n",
        "\n",
        "    return np.array(centers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ainm9aGpacnq"
      },
      "outputs": [],
      "source": [
        "def centers_for_kmeanspp(X, k):\n",
        "    centers = []\n",
        "\n",
        "    # First center\n",
        "    centers.append(X[np.random.randint(X.shape[0])])\n",
        "\n",
        "    for _ in range(1,k):\n",
        "        shortest_distance_to_center = np.array([\n",
        "            np.min([np.linalg.norm(X[i] - center)**2 for center in centers])\n",
        "            for i in range(X.shape[0])\n",
        "        ])\n",
        "\n",
        "        proba = shortest_distance_to_center / np.sum(shortest_distance_to_center)\n",
        "\n",
        "        centers.append(X[np.random.choice(range(X.shape[0]), p=proba)])\n",
        "\n",
        "    return np.array(centers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTEisv9H12s_"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgLTWder2VE7"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'face'   # face | emnist | coil20\n",
        "\n",
        "trial = 1000\n",
        "dataset_name_to_n_clusters = {'face': 40, 'emnist': 26, 'coil20': 20}\n",
        "n_clusters = dataset_name_to_n_clusters[dataset_name]\n",
        "\n",
        "s = time.time()\n",
        "\n",
        "# init = 'random' | centers_for_kmeanspp(X, n_clusters) | centers_from_pca(X, n_clusters)\n",
        "res = [KMeans(n_clusters, init=centers_from_pca(X, n_clusters), n_init=1, algorithm='lloyd').fit(X).inertia_ for _ in range(trial)]\n",
        "\n",
        "total_time = time.time() - s\n",
        "\n",
        "with open('res', 'w') as f:\n",
        "    csv.writer(f).writerow(res)\n",
        "    f.write('[[' + str(total_time) + ']]')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
